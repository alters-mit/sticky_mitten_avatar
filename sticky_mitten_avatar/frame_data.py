import numpy as np
from typing import List, Dict, Optional, Tuple
from tdw.output_data import OutputData, Rigidbodies, Images, Transforms
from tdw.py_impact import PyImpact, AudioMaterial, Base64Sound
from sticky_mitten_avatar.static_object_info import StaticObjectInfo
from sticky_mitten_avatar.avatars.avatar import Avatar
from sticky_mitten_avatar.util import get_data


class FrameData:
    """
    Per-frame data that an avatar can use to decide what action to do next.

    Fields:
    - `positions` The dictionary of object positions. Key = the object ID. Value = the position as a numpy array.
    - `audio` A list of tuples of audio generated by impacts. The first element in the tuple is a [`Base64Sound` object](https://github.com/threedworld-mit/tdw/blob/master/Documentation/python/py_impact.md#base64sound).
              The second element is the ID of the "target" (smaller) object.
    - `images` A dictionary of tuple of images mapped to the ID of the avatar that captured the image.
               The images tuple is (segmentation pass, depth pass). Either can be None.

    Access this data from the StickyMittenAvatarController:

    ```python
    from sticky_mitten_avatar import StickyMittenAvatarController

    c = StickyMittenAvatarController
    c.init_scene()

    print(c.frame.positions)
    ```
    """

    _P = PyImpact(initial_amp=0.01)

    def __init__(self, resp: List[bytes], objects: Dict[int, StaticObjectInfo], surface_material: AudioMaterial,
                 avatars: Dict[str, Avatar]):
        """
        :param resp: The response from the build.
        :param objects: Static object info per object. Key = the ID of the object in the scene.
        :param surface_material: The floor's [audio material](https://github.com/threedworld-mit/tdw/blob/master/Documentation/python/py_impact.md#audiomaterialenum).
        :param avatars: Each avatar in the scene.
        """

        self.audio: List[Tuple[Base64Sound, int]] = list()
        collisions, env_collisions, rigidbodies = FrameData._P.get_collisions(resp=resp)

        # Record avatar collisions.
        self.avatar_collisions_with_objects: Dict[str, Dict[str, int]] = dict()
        self.avatar_collisions_with_environment: Dict[str, List[str]] = dict()
        for avatar_id in avatars:
            self.avatar_collisions_with_environment[avatar_id] = avatars[avatar_id].env_collisions
            self.avatar_collisions_with_objects[avatar_id] = avatars[avatar_id].collisions

        self.positions: Dict[int, np.array] = dict()
        tr = get_data(resp=resp, d_type=Transforms)
        for i in range(tr.get_num()):
            o_id = tr.get_id(i)
            self.positions[o_id] = np.array(tr.get_position(i))

        # Get the audio of each collision.
        for coll in collisions:
            collider_id = coll.get_collider_id()
            collidee_id = coll.get_collidee_id()

            if collider_id not in objects or collidee_id not in objects:
                continue
            if not FrameData._P.is_valid_collision(coll):
                continue

            collider_info = objects[collider_id].audio
            collidee_info = objects[collidee_id].audio
            if collider_info.mass < collidee_info.mass:
                target_id = collider_id
                target_amp = collider_info.amp
                target_mat = collider_info.material.name
                other_id = collidee_id
                other_amp = collidee_info.amp
                other_mat = collider_info.material.name
            else:
                target_id = collidee_id
                target_amp = collidee_info.amp
                target_mat = collidee_info.material.name
                other_id = collider_id
                other_amp = collider_info.amp
                other_mat = collider_info.material.name
            rel_amp = other_amp / target_amp
            audio = FrameData._P.get_sound(coll, rigidbodies, other_id, other_mat, target_id, target_mat, rel_amp)
            self.audio.append((audio, target_id))
        # Get the audio of each environment collision.
        for coll in env_collisions:
            collider_id = coll.get_object_id()
            v = FrameData._get_velocity(rigidbodies, collider_id)
            if (v is not None) and (v > 0):
                collider_info = objects[collider_id].audio
                audio = FrameData._P.get_sound(coll, rigidbodies, 1, surface_material.name, collider_id,
                                               collider_info.material.name, 0.01)
                self.audio.append((audio, collider_id))
        # Get the image data.
        self.images: Dict[str, Tuple[np.array, np.array]] = dict()
        for i in range(0, len(resp) - 1):
            if OutputData.get_data_type_id(resp[i]) == "imag":
                images = Images(resp[i])
                segmentation_pass: Optional[np.array] = None
                depth_pass: Optional[np.array] = None
                for j in range(images.get_num_passes()):
                    if images.get_pass_mask(j) == "_id":
                        segmentation_pass = images.get_image(j)
                    elif images.get_pass_mask(j) == "_depth":
                        depth_pass = images.get_image(j)
                self.images[images.get_avatar_id()] = (segmentation_pass, depth_pass)

    @staticmethod
    def _get_velocity(rigidbodies: Rigidbodies, o_id: int) -> float:
        """
        :param rigidbodies: The rigidbody data.
        :param o_id: The ID of the object.

        :return: The velocity magnitude of the object.
        """

        for i in range(rigidbodies.get_num()):
            if rigidbodies.get_id(i) == o_id:
                return np.linalg.norm(rigidbodies.get_velocity(i))
